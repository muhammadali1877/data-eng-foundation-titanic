{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb96ed4-6d5b-4d88-880c-b1d3b75a1fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:(891, 12)\n",
      "\n",
      "columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "\n",
      "Memory Usage (bytes):\n",
      "Index            132\n",
      "PassengerId     7128\n",
      "Survived        7128\n",
      "Pclass          7128\n",
      "Name           67685\n",
      "Sex            47851\n",
      "Age             7128\n",
      "SibSp           7128\n",
      "Parch           7128\n",
      "Ticket         49674\n",
      "Fare            7128\n",
      "Cabin          32712\n",
      "Embarked       44514\n",
      "dtype: int64\n",
      "\n",
      "=== Missing values per column ===\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "=== Duplicate row count ===\n",
      "0\n",
      "\n",
      "=== Columns that look numeric but need checking ===\n",
      "Ticket\n",
      "\n",
      "============================================================\n",
      "COLUMN: PassengerId\n",
      "dtype: int64\n",
      "missing: 0\n",
      "unique: 891\n",
      "sample values: ['1', '2', '3', '4', '5']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Survived\n",
      "dtype: int64\n",
      "missing: 0\n",
      "unique: 2\n",
      "sample values: ['0', '1', '1', '1', '0']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Pclass\n",
      "dtype: int64\n",
      "missing: 0\n",
      "unique: 3\n",
      "sample values: ['3', '1', '3', '1', '3']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Name\n",
      "dtype: object\n",
      "missing: 0\n",
      "unique: 891\n",
      "sample values: ['Braund, Mr. Owen Harris', 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', 'Heikkinen, Miss. Laina', 'Futrelle, Mrs. Jacques Heath (Lily May Peel)', 'Allen, Mr. William Henry']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Sex\n",
      "dtype: object\n",
      "missing: 0\n",
      "unique: 2\n",
      "sample values: ['male', 'female', 'female', 'female', 'male']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Age\n",
      "dtype: float64\n",
      "missing: 177\n",
      "unique: 89\n",
      "sample values: ['22.0', '38.0', '26.0', '35.0', '35.0']\n",
      "\n",
      "============================================================\n",
      "COLUMN: SibSp\n",
      "dtype: int64\n",
      "missing: 0\n",
      "unique: 7\n",
      "sample values: ['1', '1', '0', '1', '0']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Parch\n",
      "dtype: int64\n",
      "missing: 0\n",
      "unique: 7\n",
      "sample values: ['0', '0', '0', '0', '0']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Ticket\n",
      "dtype: object\n",
      "missing: 0\n",
      "unique: 681\n",
      "sample values: ['A/5 21171', 'PC 17599', 'STON/O2. 3101282', '113803', '373450']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Fare\n",
      "dtype: float64\n",
      "missing: 0\n",
      "unique: 248\n",
      "sample values: ['7.25', '71.2833', '7.925', '53.1', '8.05']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Cabin\n",
      "dtype: object\n",
      "missing: 687\n",
      "unique: 148\n",
      "sample values: ['C85', 'C123', 'E46', 'G6', 'C103']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Embarked\n",
      "dtype: object\n",
      "missing: 2\n",
      "unique: 4\n",
      "sample values: ['S', 'C', 'S', 'S', 'S']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ------------------------- \n",
    "# Load data \n",
    "# -------------------------\n",
    "\n",
    "df= pd.read_csv(\"Titanic_train.csv\")\n",
    "\n",
    "def inspect_df():\n",
    "    print(f\"shape:{df.shape}\\n\")\n",
    "    print(f\"columns: {df.columns.tolist()}\\n\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\nMemory Usage (bytes):\")\n",
    "    print(df.memory_usage(deep=True))\n",
    "\n",
    "\n",
    "def df_quality_report():\n",
    "    print(\"\\n=== Missing values per column ===\")\n",
    "    print(df.isna().sum())\n",
    "    print(\"\\n=== Duplicate row count ===\")\n",
    "    print(df.duplicated().sum())\n",
    "    print(\"\\n=== Columns that look numeric but need checking ===\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            converted = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            if converted.notna().sum() > 0 and converted.isna().sum() > df[col].isna().sum():\n",
    "                print(col)\n",
    "\n",
    "\n",
    "inspect_df()\n",
    "df_quality_report()\n",
    "\n",
    "for c in df.columns:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COLUMN:\", c)\n",
    "    print(\"dtype:\", df[c].dtype)\n",
    "    print(\"missing:\", df[c].isna().sum())\n",
    "    print(\"unique:\", df[c].nunique(dropna=False))\n",
    "    print(\"sample values:\", df[c].dropna().astype(str).head(5).tolist())\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96261e00-31cf-4d70-8b74-acf05770ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:(418, 11)\n",
      "\n",
      "columns: ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "\n",
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "\n",
      "Memory Usage (bytes):\n",
      "Index            132\n",
      "PassengerId     3344\n",
      "Pclass          3344\n",
      "Name           31970\n",
      "Sex            22458\n",
      "Age             3344\n",
      "SibSp           3344\n",
      "Parch           3344\n",
      "Ticket         23356\n",
      "Fare            3344\n",
      "Cabin          15294\n",
      "Embarked       20900\n",
      "dtype: int64\n",
      "\n",
      "=== Missing values per column ===\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "\n",
      "=== Duplicate row count ===\n",
      "0\n",
      "\n",
      "=== Columns that look numeric but need checking ===\n",
      "Ticket\n",
      "\n",
      "============================================================\n",
      "COLUMN: PassengerId\n",
      "dtype: int64\n",
      "missing: 0\n",
      "unique: 418\n",
      "sample values: ['892', '893', '894', '895', '896']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Pclass\n",
      "dtype: int64\n",
      "missing: 0\n",
      "unique: 3\n",
      "sample values: ['3', '3', '2', '3', '3']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Name\n",
      "dtype: object\n",
      "missing: 0\n",
      "unique: 418\n",
      "sample values: ['Kelly, Mr. James', 'Wilkes, Mrs. James (Ellen Needs)', 'Myles, Mr. Thomas Francis', 'Wirz, Mr. Albert', 'Hirvonen, Mrs. Alexander (Helga E Lindqvist)']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Sex\n",
      "dtype: object\n",
      "missing: 0\n",
      "unique: 2\n",
      "sample values: ['male', 'female', 'male', 'male', 'female']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Age\n",
      "dtype: float64\n",
      "missing: 86\n",
      "unique: 80\n",
      "sample values: ['34.5', '47.0', '62.0', '27.0', '22.0']\n",
      "\n",
      "============================================================\n",
      "COLUMN: SibSp\n",
      "dtype: int64\n",
      "missing: 0\n",
      "unique: 7\n",
      "sample values: ['0', '1', '0', '0', '1']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Parch\n",
      "dtype: int64\n",
      "missing: 0\n",
      "unique: 8\n",
      "sample values: ['0', '0', '0', '0', '1']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Ticket\n",
      "dtype: object\n",
      "missing: 0\n",
      "unique: 363\n",
      "sample values: ['330911', '363272', '240276', '315154', '3101298']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Fare\n",
      "dtype: float64\n",
      "missing: 1\n",
      "unique: 170\n",
      "sample values: ['7.8292', '7.0', '9.6875', '8.6625', '12.2875']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Cabin\n",
      "dtype: object\n",
      "missing: 327\n",
      "unique: 77\n",
      "sample values: ['B45', 'E31', 'B57 B59 B63 B66', 'B36', 'A21']\n",
      "\n",
      "============================================================\n",
      "COLUMN: Embarked\n",
      "dtype: object\n",
      "missing: 0\n",
      "unique: 3\n",
      "sample values: ['Q', 'S', 'Q', 'S', 'S']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# ------------------------- \n",
    "# Load data \n",
    "# -------------------------\n",
    "\n",
    "df= pd.read_csv(\"Titanic_test.csv\")\n",
    "\n",
    "def inspect_df():\n",
    "    print(f\"shape:{df.shape}\\n\")\n",
    "    print(f\"columns: {df.columns.tolist()}\\n\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\nMemory Usage (bytes):\")\n",
    "    print(df.memory_usage(deep=True))\n",
    "\n",
    "\n",
    "def df_quality_report():\n",
    "    print(\"\\n=== Missing values per column ===\")\n",
    "    print(df.isna().sum())\n",
    "    print(\"\\n=== Duplicate row count ===\")\n",
    "    print(df.duplicated().sum())\n",
    "    print(\"\\n=== Columns that look numeric but need checking ===\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            converted = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            if converted.notna().sum() > 0 and converted.isna().sum() > df[col].isna().sum():\n",
    "                print(col)\n",
    "\n",
    "inspect_df()\n",
    "df_quality_report()\n",
    "\n",
    "for c in df.columns:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COLUMN:\", c)\n",
    "    print(\"dtype:\", df[c].dtype)\n",
    "    print(\"missing:\", df[c].isna().sum())\n",
    "    print(\"unique:\", df[c].nunique(dropna=False))\n",
    "    print(\"sample values:\", df[c].dropna().astype(str).head(5).tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf960cd2-8b25-4690-a128-37ee7796e554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (train cleaned):\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "\n",
      "Missing values (test cleaned):\n",
      "PassengerId    0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "\n",
      "Columns now:\n",
      "['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked', 'Deck']\n"
     ]
    }
   ],
   "source": [
    "# train and test data cleaned\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_path = \"Titanic_train.csv\"\n",
    "test_path  = \"Titanic_test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "# Separate target\n",
    "y = train_df[\"Survived\"]\n",
    "X_train = train_df.drop(columns=[\"Survived\"])\n",
    "X_test  = test_df.copy()\n",
    "\n",
    "def preprocess_titanic(X_train: pd.DataFrame, X_test: pd.DataFrame):\n",
    "    Xtr = X_train.copy()\n",
    "    Xte = X_test.copy()\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Embarked: fill with mode (learned from train)\n",
    "    # -------------------------\n",
    "    embarked_mode = Xtr[\"Embarked\"].mode(dropna=True)[0]\n",
    "    Xtr[\"Embarked\"] = Xtr[\"Embarked\"].fillna(embarked_mode)\n",
    "    Xte[\"Embarked\"] = Xte[\"Embarked\"].fillna(embarked_mode)\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Cabin: extract Deck, fill missing as \"Unknown\", drop Cabin\n",
    "    # -------------------------\n",
    "    Xtr[\"Deck\"] = Xtr[\"Cabin\"].astype(str).str[0].replace(\"n\", np.nan)  # 'nan' -> NaN\n",
    "    Xte[\"Deck\"] = Xte[\"Cabin\"].astype(str).str[0].replace(\"n\", np.nan)\n",
    "\n",
    "    Xtr[\"Deck\"] = Xtr[\"Deck\"].fillna(\"Unknown\")\n",
    "    Xte[\"Deck\"] = Xte[\"Deck\"].fillna(\"Unknown\")\n",
    "\n",
    "    Xtr = Xtr.drop(columns=[\"Cabin\"])\n",
    "    Xte = Xte.drop(columns=[\"Cabin\"])\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Age: group-based median by (Pclass, Sex) learned from train\n",
    "    # -------------------------\n",
    "    age_median_by_group = Xtr.groupby([\"Pclass\", \"Sex\"])[\"Age\"].median()\n",
    "\n",
    "    def fill_age(df):\n",
    "        df = df.copy()\n",
    "        # map each row to the group's median\n",
    "        group_median = df.set_index([\"Pclass\", \"Sex\"]).index.map(age_median_by_group)\n",
    "        df[\"Age\"] = df[\"Age\"].fillna(pd.Series(group_median, index=df.index))\n",
    "        # fallback (in case any group median is missing)\n",
    "        df[\"Age\"] = df[\"Age\"].fillna(Xtr[\"Age\"].median())\n",
    "        return df\n",
    "\n",
    "    Xtr = fill_age(Xtr)\n",
    "    Xte = fill_age(Xte)\n",
    "\n",
    "    return Xtr, Xte\n",
    "\n",
    "\n",
    "\n",
    "X_train_clean, X_test_clean = preprocess_titanic(X_train, X_test)\n",
    "\n",
    "fare_median = X_train_clean[\"Fare\"].median()\n",
    "X_test_clean[\"Fare\"] = X_test_clean[\"Fare\"].fillna(fare_median)\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Missing values (train cleaned):\")\n",
    "print(X_train_clean.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\nMissing values (test cleaned):\")\n",
    "print(X_test_clean.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\nColumns now:\")\n",
    "print(X_train_clean.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30bdc85c-5c80-4bd4-86bd-943b492b9d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Col           2\n",
      "Mlle          2\n",
      "Major         2\n",
      "Ms            1\n",
      "Mme           1\n",
      "Don           1\n",
      "Lady          1\n",
      "Sir           1\n",
      "Capt          1\n",
      "Countess      1\n",
      "Jonkheer      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# extract title\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_path = \"Titanic_train.csv\"\n",
    "test_path  = \"Titanic_test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "# Separate target\n",
    "y = train_df[\"Survived\"]\n",
    "X_train = train_df.drop(columns=[\"Survived\"])\n",
    "X_test  = test_df.copy()\n",
    "\n",
    "def preprocess_titanic(X_train: pd.DataFrame, X_test: pd.DataFrame):\n",
    "    Xtr = X_train.copy()\n",
    "    Xte = X_test.copy()\n",
    "\n",
    "    # -------------------------\n",
    "    # 1) Embarked: fill with mode (learned from train)\n",
    "    # -------------------------\n",
    "    embarked_mode = Xtr[\"Embarked\"].mode(dropna=True)[0]\n",
    "    Xtr[\"Embarked\"] = Xtr[\"Embarked\"].fillna(embarked_mode)\n",
    "    Xte[\"Embarked\"] = Xte[\"Embarked\"].fillna(embarked_mode)\n",
    "\n",
    "    # -------------------------\n",
    "    # 2) Cabin: extract Deck, fill missing as \"Unknown\", drop Cabin\n",
    "    # -------------------------\n",
    "    Xtr[\"Deck\"] = Xtr[\"Cabin\"].astype(str).str[0].replace(\"n\", np.nan)  # 'nan' -> NaN\n",
    "    Xte[\"Deck\"] = Xte[\"Cabin\"].astype(str).str[0].replace(\"n\", np.nan)\n",
    "\n",
    "    Xtr[\"Deck\"] = Xtr[\"Deck\"].fillna(\"Unknown\")\n",
    "    Xte[\"Deck\"] = Xte[\"Deck\"].fillna(\"Unknown\")\n",
    "\n",
    "    Xtr = Xtr.drop(columns=[\"Cabin\"])\n",
    "    Xte = Xte.drop(columns=[\"Cabin\"])\n",
    "\n",
    "    # -------------------------\n",
    "    # 3) Age: group-based median by (Pclass, Sex) learned from train\n",
    "    # -------------------------\n",
    "    age_median_by_group = Xtr.groupby([\"Pclass\", \"Sex\"])[\"Age\"].median()\n",
    "\n",
    "    def fill_age(df):\n",
    "        df = df.copy()\n",
    "        # map each row to the group's median\n",
    "        group_median = df.set_index([\"Pclass\", \"Sex\"]).index.map(age_median_by_group)\n",
    "        df[\"Age\"] = df[\"Age\"].fillna(pd.Series(group_median, index=df.index))\n",
    "        # fallback (in case any group median is missing)\n",
    "        df[\"Age\"] = df[\"Age\"].fillna(Xtr[\"Age\"].median())\n",
    "        return df\n",
    "\n",
    "    Xtr = fill_age(Xtr)\n",
    "    Xte = fill_age(Xte)\n",
    "\n",
    "    return Xtr, Xte\n",
    "\n",
    "\n",
    "\n",
    "X_train_clean, X_test_clean = preprocess_titanic(X_train, X_test)\n",
    "\n",
    "fare_median = X_train_clean[\"Fare\"].median()\n",
    "X_test_clean[\"Fare\"] = X_test_clean[\"Fare\"].fillna(fare_median)\n",
    "\n",
    "def extract_title(df):\n",
    "    df = df.copy()\n",
    "    df[\"Title\"] = df[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\", expand=False)\n",
    "    return df\n",
    "\n",
    "X_train_clean = extract_title(X_train_clean)\n",
    "X_test_clean  = extract_title(X_test_clean)\n",
    "\n",
    "# 4️⃣ Inspect Title distribution\n",
    "print(X_train_clean[\"Title\"].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# Quick sanity checks\n",
    "#print(\"Missing values (train cleaned):\")\n",
    "#print(X_train_clean.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "#print(\"\\nMissing values (test cleaned):\")\n",
    "#print(X_test_clean.isna().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "#print(\"\\nColumns now:\")\n",
    "#print(X_train_clean.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1945ea-1ad4-493a-b609-d3d3c062f6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
